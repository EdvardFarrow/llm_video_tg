
# Telegram Bot: Video Analytics (LLM + SQL)

Разработка асинхронного Telegram-бота, который преобразует запросы на естественном языке в SQL-запросы к базе данных PostgreSQL для анализа статистики видео-креаторов.

## Технологии

* **Язык:** Python 3.12
* **Telegram:** Aiogram 3.x
* **Database:** PostgreSQL 15
* **ORM/Driver:** SQLAlchemy 2.0 + AsyncPG
* **LLM:** Google Gemini 2.5 Flash
* **ETL:** Библиотека `ijson` для потокового парсинга больших JSON-файлов 
* **Infrastructure:** Docker & Docker Compose.

---

## Быстрый запуск

Проект полностью упакован в докер. Для запуска требуется установленный Docker и Docker Compose.

### 1. Клонирование репозитория
```bash
git clone https://github.com/EdvardFarrow/llm_video_tg.git
cd llm_video_tg
```

### 2. Настройка окружения
```bash
cp .env.example .env
```

### 3. Подготовка данных 

Файл с данными `videos.json` **не хранится в репозитории** (добавлен в `.gitignore`), так как содержит тяжелые тестовые данные.

1.  Скачайте файл `videos.json` из условий задания.
    
2.  Создайте папку `data/` в корне проекта (если её нет).
    
3.  Положите файл `videos.json` внутрь папки `data/`.
    

Структура должна быть такой:
```plaintext
llm_video_tg/
├── data/
│   └── videos.json  <-- Файл должен лежать здесь
├── src/
├── .env
├── docker-compose.yml
...
```

### 4. Запуск

Выполните одну команду:
```bash
docker compose up --build
```

**Что произойдет автоматически:**

1.  Поднимется контейнер с PostgreSQL.
    
2.  Бот дождется готовности базы данных.
    
3.  Скрипт миграции создаст таблицы.
    
4.  **ETL-скрипт загрузит данные** из `data/videos.json` в базу.
    
5.  Бот запустится и будет готов отвечать на сообщения.


## Решения

### 1. ETL 

Так как входной JSON может быть большим, используется библиотека `ijson`.

-   **Проблема:** Обычный `json.load()` грузит весь файл в RAM, что может вызвать OOM на больших датасетах.
    
-   **Решение:** Потоковое чтение `ijson.items` позволяет читать объекты по одному и отправлять их в БД пачками. Это позволяет обрабатывать файлы любого размера (хоть 100 ГБ) с минимальным потреблением памяти.
    

### 2. Text-to-SQL 

Бот не пытается "понять" смысл данных сам, он делегирует написание SQL нейросети.

-   **Модель:** Gemini 2.5 Flash (выбрана за скорость и низкую стоимость/бесплатные лимиты).
    
-   **System Prompt:** Содержит описание схемы БД (`videos`, `video_snapshots`) и жесткие правила:
    
    -   Идентификаторы (`id`, `creator_id`) трактуются как строки (UUID).
        
    -   Для вопросов о "приросте" используется таблица снапшотов и арифметика дельт.
        
    -   Запрещен Markdown в ответе, только чистый SQL.
        
-   **Безопасность:** LLM генерирует только `SELECT` запросы (агрегации), возвращающие одно число (`scalar`).
    

### 3. База данных

-   Используется **PostgreSQL**.
    
-   Для работы с датами используется `DateTime(timezone=True)`.
    
-   ID хранятся как `String` (так как в исходном JSON это UUID).
    
-   Добавлены индексы на поля `creator_id`, `video_id` и `created_at` для ускорения аналитических запросов.


## Структура проекта

Plaintext

```
.
├── data/                   # Папка для JSON файла
├── src/
│   ├── bot/
│   │   ├── handlers.py     # Логика обработки сообщений
│   │   └── main.py         # Точка входа
│   ├── database/
│   │   ├── models.py       # SQLAlchemy модели
│   │   └── db.py           # Настройка движка
│   ├── services/
│   │   ├── data_loader.py  # Скрипт загрузки
│   │   └── llm_service.py  # Интеграция с Gemini API
│   └── config.py           # Pydantic Settings
├── entrypoint.sh           # Скрипт инициализации для Docker
├── Dockerfile
├── docker-compose.yml
└── requirements.txt
```